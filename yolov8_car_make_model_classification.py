"""YOLOv8 Car Make-Model Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11w-qdO4m9RiOV-Dlh5No3oeAshxljLg2

#Coding Test: Train a YOLOv8 Classification Model for Car Make-Model
by Hafiz (Produced on 26 Aug 2024)

## 1. Dataset Preparation

1. **Download the Dataset**: You'll need to download the dataset from the provided link.
2. **Organize the Dataset**: After downloading, we need to extract the dataset and organize it into train and validation sets.
3. **Splitting the Dataset**: The dataset isn't split into train and validation sets, we will need to do this manually.
"""

import os
import tarfile
import gdown
import shutil
from sklearn.model_selection import train_test_split
from ultralytics import YOLO
import numpy as np

def extract_file_id(drive_link):
    # Split the link based on '/d/' and '/view' to isolate the file ID
    try:
        file_id = drive_link.split('/d/')[1].split('/view')[0]
        return file_id
    except IndexError:
        return None

def extract_tgz_file(tgz_file, output_dir):
    # Check if the output directory exists, if not, create it
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Open the .tgz file and extract all contents
    with tarfile.open(tgz_file, "r:gz") as tar:
        tar.extractall(path=output_dir)
    print(f"Extracted {tgz_file} successfully to {output_dir}.")

def count_files_in_directory(directory):
    total_files = 0
    for root, dirs, files in os.walk(directory):
        total_files += len(files)
    return total_files

drive_link = 'https://drive.google.com/file/d/146rPq89DbjnyzevKwguwuxwkItbNhQvN/view'
test_size = 0.2

gdown.download(f'https://drive.google.com/uc?id={extract_file_id(drive_link)}', 'made_model.tgz', quiet=False)

tgz_file = 'made_model.tgz'  # Path to your .tgz file
output_directory = 'car_model'  # Directory where you want to extract the contents

extract_tgz_file(tgz_file, output_directory)

# Set the paths
dataset_dir = 'car_model/made_model'
output_dir = 'car_model'

train_dir = os.path.join(output_dir, 'train')
val_dir = os.path.join(output_dir, 'val')

# Ensure the output directories exist
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

# Iterate over each class folder in the dataset
for class_name in os.listdir(dataset_dir):
    class_dir = os.path.join(dataset_dir, class_name)

    if os.path.isdir(class_dir):
        images = os.listdir(class_dir)

        # Split the images into train and validation sets
        train_images, val_images = train_test_split(images, test_size=test_size, random_state=42)

        # Copy the images to the respective folders
        train_class_dir = os.path.join(train_dir, class_name)
        val_class_dir = os.path.join(val_dir, class_name)

        os.makedirs(train_class_dir, exist_ok=True)
        os.makedirs(val_class_dir, exist_ok=True)

        for img in train_images:
            shutil.copy(os.path.join(class_dir, img), os.path.join(train_class_dir, img))

        for img in val_images:
            shutil.copy(os.path.join(class_dir, img), os.path.join(val_class_dir, img))

shutil.rmtree('car_model/made_model')

print("Dataset successfully split into train and validation sets.")

print(f"Number of training images: {count_files_in_directory(train_dir)}")
print(f"Number of validation images: {count_files_in_directory(val_dir)}")

model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model
model.to('cuda')
results = model.train(data='car_model', epochs=5)  # train the model

uploaded_files = 'images'
model = YOLO('/content/runs/classify/train/weights/best.pt')
results = model(uploaded_files)

# Access the probabilities object
probs = results[0].probs.data.cpu()

# Get the index of the class with the highest probability
highest_prob_index = int(np.argmax(probs))

# Get the class name with the highest confidence
class_name = results[0].names[highest_prob_index]

print(f"Car type: {class_name}")

model = YOLO("/content/runs/classify/train/weights/best.pt")
model.export(
    format="engine",
    dynamic=True,
    batch=8,
    workspace=4,
    int8=True,
    data="car_model",
)

# Load the exported TensorRT INT8 model
model = YOLO("/content/runs/classify/train/weights/best.engine", task="classify")

# Run inference
result = model.predict("/content/PERODUA_Axia-2019_main.jpg")

# Load the exported TensorRT INT8 model
model = YOLO("/content/runs/classify/train/weights/best.engine", task="classify")

# Run inference
result = model.predict("/content/PERODUA_Axia-2019_main.jpg")

# Access the probabilities object
probs = result[0].probs.data.cpu()

# Get the index of the class with the highest probability
highest_prob_index = int(np.argmax(probs))

# Get the class name with the highest confidence
class_name = results[0].names[highest_prob_index]

print(f"Car type: {class_name}")